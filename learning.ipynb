{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pandas import read_csv\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "input_dim = 5  # one-hot size\n",
    "hidden_size = 4  # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 50   # one sentence\n",
    "sequence_length = 5  # |ihello| == 6\n",
    "learning_rate = 0.0001\n",
    "data_mean = 0\n",
    "data_std = 0\n",
    "epoch_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 200, 400, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 4])\n",
    "\n",
    "with tf.variable_scope(\"cnn\"):\n",
    "    \n",
    "    # conv : 5, 200, 400, 16\n",
    "    conv = tf.layers.conv2d(inputs=X, filters=16, kernel_size=[4, 8], padding='SAME', activation=tf.nn.relu)\n",
    "    # pool : 5, 50, 99, 16\n",
    "    pool = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 4], padding='SAME', strides=1)\n",
    "    # conv2 \n",
    "    conv2 = tf.layers.conv2d(inputs=pool, filters=32, kernel_size=[4, 8], padding='SAME', activation=tf.nn.relu)\n",
    "    # pool2 \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[4, 8], padding='SAME', strides=2)\n",
    "    # conv3\n",
    "    conv3 = tf.layers.conv2d(inputs=pool2, filters=64, kernel_size=[4, 8], padding='SAME', activation=tf.nn.relu)\n",
    "    # pool3 \n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[4, 8], padding='SAME', strides=2)\n",
    "    \n",
    "    flat = tf.reshape(pool3, [-1, 100*200*16])\n",
    "    w = tf.get_variable(\"w\", [hidden_size, hidden_size])\n",
    "    b = tf.get_variable(\"b\", [hidden_size])\n",
    "    \n",
    "    logit = tf.layers.dense(inputs=flat, units=4)\n",
    "    outputs = tf.sigmoid(tf.matmul(logit, w) + b)\n",
    "    \n",
    "    loss = -tf.reduce_mean(Y*tf.log(outputs)+(1-Y)*(tf.log(1-outputs)))\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want addtional learning? (Name or Enter)\n",
      "Model_Name: canny\n",
      "2.344409\n",
      "2.216366\n",
      "1.151917\n",
      "0.80789435\n",
      "0.97091895\n",
      "2.0135348\n",
      "1.2161217\n",
      "0.84414095\n",
      "0.6426732\n",
      "0.8790097\n",
      "1.105016\n",
      "0.4700296\n",
      "0.76179564\n",
      "0.6246805\n",
      "0.5945396\n",
      "0.58050805\n",
      "0.5473862\n",
      "0.5213024\n",
      "0.5332062\n",
      "0.5475577\n",
      "0.43923628\n",
      "0.5386374\n",
      "0.47624627\n",
      "0.57723165\n",
      "0.49985132\n",
      "0.49213096\n",
      "0.49181363\n",
      "0.44762132\n",
      "0.56400865\n",
      "0.4017074\n",
      "0.46920487\n",
      "0.43472838\n",
      "0.5175881\n",
      "0.50744694\n",
      "0.518704\n",
      "0.47193706\n",
      "0.4653421\n",
      "0.42204997\n",
      "0.6019022\n",
      "0.44714946\n",
      "0.4222723\n",
      "0.40721118\n",
      "0.55012506\n",
      "0.7239358\n",
      "0.38824722\n",
      "0.54583377\n",
      "0.48886895\n",
      "0.48340073\n",
      "0.47412652\n",
      "0.50118303\n",
      "0.43950957\n",
      "0.4535171\n",
      "0.48150274\n",
      "0.4501683\n",
      "0.46568093\n",
      "0.45287162\n",
      "0.3948114\n",
      "0.478226\n",
      "0.5680326\n",
      "0.4563229\n",
      "0.47975457\n",
      "0.5066128\n",
      "0.46818405\n",
      "0.4342106\n",
      "0.49282464\n",
      "0.46191493\n",
      "0.4544577\n",
      "0.42532143\n",
      "0.4077855\n",
      "0.54344445\n",
      "0.41693923\n",
      "0.41050556\n",
      "0.2895173\n",
      "0.34275645\n",
      "0.35514328\n",
      "0.43348098\n",
      "0.589435\n",
      "0.42112786\n",
      "0.30955148\n",
      "0.41171002\n",
      "0.47715974\n",
      "0.45146033\n",
      "0.3735811\n",
      "0.43061942\n",
      "0.36722553\n",
      "0.40237504\n",
      "0.38164234\n",
      "0.35665005\n",
      "0.2890034\n",
      "0.35305348\n",
      "0.35778007\n",
      "0.43838242\n",
      "0.54792476\n",
      "0.5271861\n",
      "0.33226186\n",
      "0.3450917\n",
      "0.36581907\n",
      "0.4161207\n",
      "0.45912713\n",
      "0.40538493\n",
      "0.38221565\n",
      "0.45170644\n",
      "0.50062853\n",
      "0.35102957\n",
      "0.4086861\n",
      "0.48663494\n",
      "0.45830184\n",
      "0.43525344\n",
      "0.4829097\n",
      "0.33545056\n",
      "0.49508286\n",
      "0.4862035\n",
      "0.4923153\n",
      "0.41662437\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "cannot identify image file './imgs/img4/1720.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-83075fc95fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./imgs/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/tensorflow/local/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2588\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2590\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: cannot identify image file './imgs/img4/1720.jpg'"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = raw_input(\"Do you want addtional learning? (Name or Enter)\")\n",
    "    if res:\n",
    "        saver.restore(sess, \"./model/\"+res+\".ckpt\")\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    model_name = raw_input(\"Model_Name: \")\n",
    "    \n",
    "    data_names = [x[:-4] for x in listdir('./logs') if x[-4:]=='.csv']\n",
    "    \n",
    "    with open('./logs/norm.txt', 'r') as f:\n",
    "        data_mean = float(f.readline())\n",
    "        data_std = float(f.readline())\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epoch_num):\n",
    "            \n",
    "            for data_name in data_names:\n",
    "\n",
    "                data_df = read_csv('./logs/'+data_name+'.csv', names=['name','key_out'])\n",
    "                names = data_df['name'].values\n",
    "                # keyouts = [8, 1, 4, 2, 15, ...]\n",
    "                key_out = [eval(x) for x in data_df['key_out'].values]\n",
    "\n",
    "                while len(names):\n",
    "                    imgs = []\n",
    "                    offset = min(batch_size, len(names))\n",
    "                    batch_x = names[0:offset]\n",
    "                    batch_y = key_out[0:offset]\n",
    "                    names = names[offset:]\n",
    "                    key_out = key_out[offset:]\n",
    "\n",
    "                    for name in batch_x:\n",
    "                        img = Image.open('./imgs/'+data_name+'/'+name)\n",
    "                        data = np.array( img, dtype='uint8')\n",
    "                        data = data.reshape([200,400,1])\n",
    "                        data = (data-data_mean) / data_std\n",
    "                        imgs.append(data)\n",
    "                    sess.run(train, feed_dict={X:np.array(imgs, np.float32), Y:batch_y})\n",
    "                    print sess.run(loss, feed_dict={X:np.array(imgs, np.float32), Y:batch_y})\n",
    "            save_path = saver.save(sess, \"./model/\"+model_name+\"_\"+str(epoch+1)+\".ckpt\")\n",
    "            print 'epoch', epoch+1, sess.run(loss, feed_dict={X:np.array(imgs, np.float32), Y:batch_y})\n",
    "    except:\n",
    "        save_path = saver.save(sess, \"./model/\"+model_name+\"_ex.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
